{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "PATH='data/zebestof/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographic prediction\n",
    "\n",
    "When a user visits our websites, we collect information about keywords extracted from the website's url. For each user, the frequency of visits per word per day is also stored. \n",
    "For example, suppose that a given user has visited the two following sites today:\n",
    "- html://figaro/abc-news/aaa-bbb.html html://figaro/news/aaa.html\n",
    "\n",
    "The keywords “seen” by this user will be then stored as follows (semicolon is used to separate words):\n",
    "abc:1; news:2; aaa:2; bbb:1\n",
    "\n",
    "We have demographics information (like age, sex) on about 10% of our visitors, thanks to external data (or other sources of information).\n",
    "\n",
    "The Head of Product wanted to predict demographics (age, sex) for the rest of our visitors from the keywords collected. He then spoke to Mr. Google, who advised him to hire a talented data scientist, in order to transform his idea into reality. And now, you understand why you are here today!\n",
    "\n",
    "So, he's asked you to build a machine learning model, which can help us predict age and sex for each line in our dataset, which was partially extracted from one month's data (the portion of each day's data was concatenated). The dataset contains two files named train.csv (to help you train your model) and test.csv. Its format looks like: userID, keywords, age, sex (comma is used as a delimiter). Note that there are some missing data in our dataset, and we removed the ID, labels (age, sex) from the test file.\n",
    "\n",
    "Once your model is trained, you have to use the test.csv file to test your model, and send us the results as a csv file containing only three columns: ID, age_pred, sex_pred. For example, your submission file should look like:\n",
    "\n",
    "ID, age_pred, sex_pred \n",
    "\n",
    "1234,35,F\n",
    "\n",
    "3456,45,M\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "- \n",
    "\n",
    "## TO DO\n",
    "\n",
    "\n",
    "- TF IDF\n",
    "- 10-fold cross-validation\n",
    "- find why cant convert to dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1.csv  train1.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f'{PATH}train1.csv')\n",
    "test_df = pd.read_csv(f'{PATH}test1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration and basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>keywords</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>fibre:16;quoi:1;dangers:1;combien:1;hightech:1...</td>\n",
       "      <td>62</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>restaurant:1;marrakech.shtml:1</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>payer:1;faq:1;taxe:1;habitation:1;macron:1;qui...</td>\n",
       "      <td>45</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>rigaud:3;laurent:3;photo:11;profile:8;photopro...</td>\n",
       "      <td>46</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>societe:1;disparition:1;proche:1;m%c3%a9lanie....</td>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                           keywords  age sex\n",
       "0   1  fibre:16;quoi:1;dangers:1;combien:1;hightech:1...   62   F\n",
       "1   2                     restaurant:1;marrakech.shtml:1   35   M\n",
       "2   3  payer:1;faq:1;taxe:1;habitation:1;macron:1;qui...   45   F\n",
       "3   4  rigaud:3;laurent:3;photo:11;profile:8;photopro...   46   F\n",
       "4   5  societe:1;disparition:1;proche:1;m%c3%a9lanie....   42   F"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>keywords</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>cecilia.gosselin:1;flash:1;ville:1;obseques:1;...</td>\n",
       "      <td>44</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>p1_1697235:1;peut:1;jcms:1;les:1;acceptees:1;p...</td>\n",
       "      <td>71</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>002lundu83vnndv:1</td>\n",
       "      <td>42</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>high:3;patisserie:1;apple:3;tech:3;obseques:1;...</td>\n",
       "      <td>44</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>disparition:1;vue:1;maelys:1;deuxieme:1;place:...</td>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                           keywords  age sex\n",
       "0   1  cecilia.gosselin:1;flash:1;ville:1;obseques:1;...   44   M\n",
       "1   2  p1_1697235:1;peut:1;jcms:1;les:1;acceptees:1;p...   71   M\n",
       "2   3                                  002lundu83vnndv:1   42   M\n",
       "3   4  high:3;patisserie:1;apple:3;tech:3;obseques:1;...   44   M\n",
       "4   5  disparition:1;vue:1;maelys:1;deuxieme:1;place:...   48   F"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.head(), test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN\n",
    "train_df = train_df.dropna(axis=0)\n",
    "test_df = test_df.dropna(subset=['keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6418659, 2748743)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By dropping NaN we lost around 800k in training and 350k in test.\n",
    "(len(train_df), len(test_df))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "common_keywords = list(set(train_df.keywords.unique()).intersection(test_df.keywords.unique()))\n",
    "print(\"Number of common keywords: \", len(common_keywords))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "age_ids = train_df.groupby('age')['ID'].count()\n",
    "sex_ids = train_df.groupby('sex')['ID'].count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Reduce age to 14-80 \n",
    "age_ids = age_ids[:67]\n",
    "plt.figure(figsize=(30,8))\n",
    "sns.barplot(age_ids.index, age_ids.values, )\n",
    "\n",
    "plt.xlabel('Number of clients', fontsize=12)\n",
    "plt.ylabel('Age', fontsize=12)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# The distribution of the number of chars in keywords.\n",
    "lens_train = train_df.keywords.str.len()\n",
    "lens_train.mean(), lens_train.std(), lens_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF - IDF\n",
    "### BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['class'] = train_df[\"age\"].map(str) + train_df[\"sex\"]\n",
    "train_df = train_df.drop(train_df.columns[[0, 2, 3]], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fibre:16;quoi:1;dangers:1;combien:1;hightech:1...</td>\n",
       "      <td>62F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>restaurant:1;marrakech.shtml:1</td>\n",
       "      <td>35M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>payer:1;faq:1;taxe:1;habitation:1;macron:1;qui...</td>\n",
       "      <td>45F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rigaud:3;laurent:3;photo:11;profile:8;photopro...</td>\n",
       "      <td>46F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>societe:1;disparition:1;proche:1;m%c3%a9lanie....</td>\n",
       "      <td>42F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            keywords class\n",
       "0  fibre:16;quoi:1;dangers:1;combien:1;hightech:1...   62F\n",
       "1                     restaurant:1;marrakech.shtml:1   35M\n",
       "2  payer:1;faq:1;taxe:1;habitation:1;macron:1;qui...   45F\n",
       "3  rigaud:3;laurent:3;photo:11;profile:8;photopro...   46F\n",
       "4  societe:1;disparition:1;proche:1;m%c3%a9lanie....   42F"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'societe:1;disparition:1;proche:1;m%c3%a9lanie.gonidec:1;maelys:1;actualite:1;affich:1;repondre:1;douleurs:1;hypothyroidie:1;forum:1;profile:1;les:1;suspectent:1;articulaires:1;gendarmes:1;questions:1;marie:1;muscu:1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['keywords'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dict to list of words without count \n",
    "def convert_to_words(keywords):\n",
    "    list_of_words = []\n",
    "    for x in keywords:\n",
    "        list_of_words.append(x.split(\":\",1)[0])\n",
    "    \n",
    "    return list_of_words\n",
    "\n",
    "\n",
    "# Convert dict to big string of words \n",
    "def convert_to_text(keywords):\n",
    "    list_of_words = []\n",
    "    for x in keywords:\n",
    "        numb_iter = int(keywords[x])\n",
    "        for k in range(numb_iter):\n",
    "            list_of_words.append(x)\n",
    "    \n",
    "    return ' '.join(list_of_words)\n",
    "\n",
    "\n",
    "def create_dict(keywords):\n",
    "    return dict(x.split(':') for x in keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_df['keywords'] = x_df['keywords'].apply(lambda row: dict(x.split(':') for x in row.split(\";\")))\n",
    "#x_df['keywords'] = x_df['keywords'].apply(lambda row: convert_to_text(row))\n",
    "\n",
    "x_df['keywords'] = x_df['keywords'].apply(lambda row: row.split(\";\"))\n",
    "x_df['keywords'] = x_df['keywords'].apply(lambda row: convert_to_words(row))\n",
    "x_df['keywords'] = x_df['keywords'].apply(lambda row: ' '.join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'football actualites les pays france equipe direct demonstration video buts bas francaise'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df['keywords'][300]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "v = DictVectorizer()\n",
    "X = v.fit_transform(x_df['keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_df[\"keywords\"]\n",
    "y = x_df[\"class\"]\n",
    "\n",
    "\n",
    "X_train_df, X_test_df, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, min_df = 30)\n",
    "# vectorizer = DictVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train_df)\n",
    "X_test = vectorizer.transform(X_test_df)\n",
    "\n",
    "\n",
    "# mapping from integer feature name to original token string\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51395"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "results = []\n",
    "\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    #print(\"classification report:\")\n",
    "    #print(metrics.classification_report(y_test, pred))\n",
    "\n",
    "    #print(\"confusion matrix:\")\n",
    "    #print(metrics.confusion_matrix(y_test, pred))\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "# Train SGD model\n",
    "print(\"SGDClassifier\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50, penalty=penalty)))\n",
    "\n",
    "print(\"Ridge Classifier\")\n",
    "results.append(benchmark(LinearSVC(penalty=\"l2\", dual=False, tol=1e-3)))\n",
    "\n",
    "print(\"Ridge Classifier\")\n",
    "results.append(benchmark(RidgeClassifier(tol=1e-2, solver=\"lsqr\")))\n",
    "    \n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50, penalty=\"elasticnet\")))\n",
    "\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "\n",
    "\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n",
    "                                                  tol=1e-3))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.032\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Pipeline definition\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(sublinear_tf=True, max_df=0.5, min_df = 30)),\n",
    "    ('classifier', MultinomialNB(alpha=.01)),\n",
    "])\n",
    "\n",
    "# Cross validate using k-fold\n",
    "y_pred = cross_val_predict(\n",
    "    pipeline, X_train, y_train, cv=10, n_jobs=-1, verbose=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/pool.py\", line 405, in _handle_workers\n",
      "    pool._maintain_pool()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/pool.py\", line 246, in _maintain_pool\n",
      "    self._repopulate_pool()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/pool.py\", line 239, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/popen_fork.py\", line 26, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/popen_fork.py\", line 73, in _launch\n",
      "    self.pid = os.fork()\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 362, in get\n",
      "    return recv()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Cross validate using k-fold\n",
    "clf = MultinomialNB(alpha=.01)\n",
    "y_pred = cross_val_predict(\n",
    "    clf, X_train, y_train, cv=10, n_jobs=-1, verbose=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032336967529048119"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute precison, recall and f1 scode.\n",
    "cr = classification_report(y, y_pred, digits=3)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Printing Classification Report\n",
    "print('{label:>{length}}'.format(\n",
    "    label='Classification Report',\n",
    "    length=159\n",
    "), cr, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df2 = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df2['keywords'] = test_df2['keywords'].apply(lambda row: row.split(\";\"))\n",
    "test_df2['keywords'] = test_df2['keywords'].apply(lambda row: convert_to_words(row))\n",
    "test_df2['keywords'] = test_df2['keywords'].apply(lambda row: ' '.join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df2['keywords'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vectorizer.transform(test_df2['keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"prediction\"] = pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"sex\"] = test_df[\"prediction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_df.to_csv('test_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['sex'] = test_df['sex'].apply(lambda row: re.sub(\"\\d+\", \"\", row))\n",
    "test_df['age'] = test_df['age'].apply(lambda row: re.sub(\"\\D+\", \"\", row))\n",
    "\n",
    "test_df = test_df.drop(['prediction'] , axis=1)\n",
    "test_df = test_df.drop(['keywords'] , axis=1)\n",
    "test_df[\"ID\"] = test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(f'{PATH}test1.csv', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(f'{PATH}test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
